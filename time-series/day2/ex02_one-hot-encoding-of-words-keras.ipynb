{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCxdAZ39HgFC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ItaQRbsHN7h"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 초기 데이터: 각 원소가 샘플입니다\n",
    "# (이 예에서 하나의 샘플이 하나의 문장입니다. 하지만 문서 전체가 될 수도 있습니다)\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# 데이터에 있는 모든 토큰의 인덱스를 구축합니다\n",
    "token_index = {} # word-to-index 매핑\n",
    "index_to_word = {} # index_to_word 매핑\n",
    "index_to_word[0] = '' # index 0번은 사용하지 않음.\n",
    "\n",
    "for sample in samples:\n",
    "    # split() 메서드를 사용해 샘플을 토큰으로 나눕니다.\n",
    "    # 실전에서는 구둣점과 특수 문자도 사용합니다.\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            # 단어마다 고유한 인덱스를 할당합니다.\n",
    "            idx = len(token_index) + 1\n",
    "            token_index[word] = idx\n",
    "            index_to_word[idx] = word\n",
    "            \n",
    "            # 인덱스 0은 사용하지 않습니다.\n",
    "\n",
    "# 샘플을 벡터로 변환합니다.\n",
    "# 각 샘플에서 max_length 까지 단어만 사용합니다.\n",
    "max_length = 10\n",
    "\n",
    "# 결과를 저장할 배열입니다\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1558423031239,
     "user": {
      "displayName": "한대희",
      "photoUrl": "",
      "userId": "17475105266749362233"
     },
     "user_tz": -540
    },
    "id": "8XB4OxKaKvfk",
    "outputId": "2fd00210-3630-484c-9f20-260819dad9d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니크 단어의 개수: 9\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# 가장 빈도가 높은 10개의 단어만 선택하도록 Tokenizer 객체를 만듭니다.\n",
    "tokenizer = Tokenizer(num_words=10)\n",
    "# 단어 인덱스를 구축합니다.\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# 문자열을 정수 인덱스의 리스트로 변환합니다.\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "# 직접 원-핫 이진 벡터 표현을 얻을 수 있습니다.\n",
    "# 원-핫 인코딩 외에 다른 벡터화 방법들도 제공합니다!\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "\n",
    "# 계산된 단어 인덱스를 구합니다.\n",
    "word_to_index = tokenizer.word_index\n",
    "print('유니크 단어의 개수: %s' % len(word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5k8O5RjrHqb2"
   },
   "source": [
    "##  word-2-index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1558422775885,
     "user": {
      "displayName": "한대희",
      "photoUrl": "",
      "userId": "17475105266749362233"
     },
     "user_tz": -540
    },
    "id": "6OCeI27bL3Gh",
    "outputId": "e41b2bc4-62a9-494a-b3b8-36f0cd4d2247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1558422776652,
     "user": {
      "displayName": "한대희",
      "photoUrl": "",
      "userId": "17475105266749362233"
     },
     "user_tz": -540
    },
    "id": "wqoNpyDOHywR",
    "outputId": "9c68c982-b188-46a8-f27d-e5fe68dd4d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 the --> 숫자 1\n",
      "단어 cat --> 숫자 2\n",
      "단어 sat --> 숫자 3\n",
      "단어 on --> 숫자 4\n",
      "단어 mat --> 숫자 5\n",
      "단어 dog --> 숫자 6\n",
      "단어 ate --> 숫자 7\n",
      "단어 my --> 숫자 8\n",
      "단어 homework --> 숫자 9\n"
     ]
    }
   ],
   "source": [
    "for word, idx in word_to_index.items():\n",
    "  print('단어', word, '-->', '숫자', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1558423092785,
     "user": {
      "displayName": "한대희",
      "photoUrl": "",
      "userId": "17475105266749362233"
     },
     "user_tz": -540
    },
    "id": "Q2X_IOG-HuWZ",
    "outputId": "bf673700-df73-4770-c421-e2bb3cbd54c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 문장 0\n",
      "문장  The cat sat on the mat.\n",
      "문장 index들 [1, 2, 3, 4, 1, 5]\n",
      "문장 인코딩 [0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "== 문장 1\n",
      "문장  The dog ate my homework.\n",
      "문장 index들 [1, 6, 7, 8, 9]\n",
      "문장 인코딩 [0. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(2):\n",
    "  print('== 문장', i)\n",
    "  print('문장 ', samples[i])\n",
    "  print('문장 index들', sequences[i])\n",
    "  print('문장 인코딩', one_hot_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1558423054281,
     "user": {
      "displayName": "한대희",
      "photoUrl": "",
      "userId": "17475105266749362233"
     },
     "user_tz": -540
    },
    "id": "i39scKSSJsvw",
    "outputId": "ff292265-858d-43f5-90bc-8edea27ea61a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ciOPbX89QKOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex02_one-hot-encoding-of-words-keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
